{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with tensors\n",
    "import torch   \n",
    "\n",
    "#handling text data\n",
    "from torchtext.legacy import data\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducing same results\n",
    "SEED = 10\n",
    "\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Cuda algorithms\n",
    "torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/anaconda3/lib/python3.8/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True, lower=True)\n",
    "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n",
    "fields = [('label', LABEL), ('text',TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'ADD_INFO', 'text': ['i', 'love', 'museums']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'would', 'like', 'to', 'be', 'outside']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'love', 'to', 'be', 'outdoors']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'are', 'a', 'group']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'want', 'something', 'close']}\n",
      "{'label': 'ADD_INFO', 'text': ['what', 'can', 'we', 'do', 'on', 'the', 'weekend']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'are', 'visiting', 'for', 'the', 'weekend']}\n",
      "{'label': 'ADD_INFO', 'text': ['my', 'kids', 'are', 'hungry']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'are', 'tired']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'like', 'art']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'love', 'the', 'beach']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'want', 'to', 'try', 'local', 'cuisine']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'want', 'to', 'listen', 'to', 'music']}\n",
      "{'label': 'ADD_INFO', 'text': ['is', 'there', 'live', 'music']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'want', 'to', 'try', 'spanish', 'wine']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'like', 'local', 'wine']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'like', 'dancing']}\n",
      "{'label': 'ADD_INFO', 'text': ['my', 'husbund', 'will', 'join', 'later']}\n",
      "{'label': 'ADD_INFO', 'text': ['my', 'girlfirend', 'will', 'come', 'later']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'love', 'good', 'food']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'want', 'to', 'see', 'sagrada', 'familia']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'just', 'want', 'to', 'ask', 'for', 'directions']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'want', 'to', 'see', 'flamenco']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'like', 'vegetarian', 'food', 'place']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'have', 'young', 'children']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'come', 'with', 'my', 'husband', 'and', 'three', 'children']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'come', 'with', 'my', 'wife']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'have', 'two', 'kids']}\n",
      "{'label': 'ADD_INFO', 'text': ['my', 'son', 'is', 'eight', 'and', 'my', 'daughter', 'is', 'twelve']}\n",
      "{'label': 'ADD_INFO', 'text': ['my', 'son', 'is', 'eleven', 'and', 'my', 'daughter', 'is', 'five']}\n",
      "{'label': 'ADD_INFO', 'text': ['that', \"'s\", 'our', 'last', 'day', 'in', 'barcelona']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'came', 'here', 'on', 'monday']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', 'just', 'arrived', 'today']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', \"'ll\", 'be', 'a', 'week', 'around', 'here']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', \"'ll\", 'stay', 'here', 'three', 'days']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'want', 'something', 'free']}\n",
      "{'label': 'ADD_INFO', 'text': ['i', 'want', 'to', 'do', 'something', 'that', 'does', \"n't\", 'cost', 'money']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', \"'re\", 'five', 'of', 'us']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', \"'re\", 'three', 'friends']}\n",
      "{'label': 'ADD_INFO', 'text': ['we', \"'ve\", 'just', 'married']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'ca', \"n't\", 'eat', 'meat']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'ca', \"n't\", 'stand', 'museums']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'like', 'the', 'crowd']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'prefer', 'not', 'to', 'go', 'far']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'want', 'food']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'like', 'music']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'had', 'a', 'bad', 'experience', 'with', 'theatres']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'want', 'to', 'be', 'outside']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'like', 'churches']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'hate', 'architecture']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'want', 'to', 'pay', 'for', 'anything']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'want', 'anything', 'expensive']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'would', 'hate', 'to', 'have', 'to', 'walk']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'like', 'paintings']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'hate', 'alcohol']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['he', 'hates', 'walking', 'too', 'much']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'like', 'museums']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'want', 'anything', 'to', 'do', 'with', 'bullfighting']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'hate', 'parks']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['my', 'children', 'prefer', 'not', 'to', 'visit', 'churches']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['she', 'does', \"n't\", 'like', 'parks']}\n",
      "{'label': 'ADD_INFO_NEG', 'text': ['i', 'do', \"n't\", 'want', 'to', 'spend', 'much']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['i', 'adore', 'art']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['my', 'child', 'loves', 'the', 'beach']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['my', 'kids', 'love', 'to', 'eat']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['i', 'ca', \"n't\", 'wait', 'to', 'visit', 'sagrada', 'familia']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['i', 'would', \"n't\", 'want', 'to', 'miss', 'the', 'wine']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['i', 'came', 'only', 'for', 'the', 'great', 'wine']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['i', 'must', 'visit', 'some', 'museums']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['i', 'like', 'museums']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['i', 'love', 'chocolate']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['my', 'daughter', 'loves', 'animals']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['my', 'girlfriend', 'loves', 'paintings']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['my', 'kids', 'love', 'football']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['she', 'likes', 'tall', 'buildings']}\n",
      "{'label': 'ADD_INFO_POS', 'text': ['we', 'like', 'art', 'and', 'science']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'are', 'the', 'options', 'for', 'the', 'museums', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'restaurants', 'are', 'newar', 'here', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'can', 'we', 'do', 'today']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['any', 'museums', 'open', 'on', 'the', 'weekend', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['is', 'there', 'anything', 'we', 'can', 'do', 'right', 'now', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['i', \"'m\", 'looking', 'for', 'a', 'recommendation', 'for', 'a', 'museum']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['can', 'you', 'tell', 'me', 'where', 'i', 'can', 'find', 'good', 'food', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['can', 'you', 'tell', 'us', 'where', 'the', 'best', 'museums', 'are']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['we', 'want', 'something', 'close']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'can', 'we', 'do', 'on', 'the', 'weekend']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['where', 'is', 'the', 'restaurant']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'can', 'we', 'do', 'in', 'this', 'neighbourhood']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['where', 'can', 'i', 'get', 'a', 'coffee']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['we', \"'re\", 'looking', 'for', 'something', 'cheap']}\n",
      "{'label': 'CONFIRM', 'text': ['awesome']}\n",
      "{'label': 'CONFIRM', 'text': ['si']}\n",
      "{'label': 'CONFIRM', 'text': ['perfect']}\n",
      "{'label': 'CONFIRM', 'text': ['terrific']}\n",
      "{'label': 'CONFIRM', 'text': ['i', 'like', 'that']}\n",
      "{'label': 'CONFIRM', 'text': ['that', 'sounds', 'interesting']}\n",
      "{'label': 'CONFIRM', 'text': ['i', 'love', 'it']}\n",
      "{'label': 'CONFIRM', 'text': ['exactly']}\n",
      "{'label': 'CONFIRM', 'text': ['hundred', 'percent']}\n",
      "{'label': 'CONFIRM', 'text': ['of', 'course']}\n",
      "{'label': 'CONFIRM', 'text': ['why', 'not']}\n",
      "{'label': 'CONFIRM', 'text': ['let', \"'s\", 'do', 'it']}\n",
      "{'label': 'CONFIRM', 'text': ['fine']}\n",
      "{'label': 'CONFIRM', 'text': ['for', 'sure']}\n",
      "{'label': 'CONFIRM', 'text': ['great', 'thank', 'you']}\n",
      "{'label': 'CONFIRM', 'text': ['it', 'looks', 'cool']}\n",
      "{'label': 'CONFIRM', 'text': ['it', 'looks', 'fine']}\n",
      "{'label': 'CONFIRM', 'text': ['ok']}\n",
      "{'label': 'CONFIRM', 'text': ['okay', 'thank', 'you']}\n",
      "{'label': 'CONFIRM', 'text': ['sounds', 'fine']}\n",
      "{'label': 'CONFIRM', 'text': ['sure']}\n",
      "{'label': 'CONFIRM', 'text': ['that', \"'s\", 'cool']}\n",
      "{'label': 'CONFIRM', 'text': ['yeah']}\n",
      "{'label': 'CONFIRM', 'text': ['yes']}\n",
      "{'label': 'CONFIRM', 'text': ['yes', 'sound', 'great']}\n",
      "{'label': 'GOODBYE', 'text': ['bye']}\n",
      "{'label': 'GOODBYE', 'text': ['bye', 'bye']}\n",
      "{'label': 'GOODBYE', 'text': ['adios']}\n",
      "{'label': 'GOODBYE', 'text': ['good', 'bye']}\n",
      "{'label': 'GOODBYE', 'text': ['see', 'you']}\n",
      "{'label': 'GOODBYE', 'text': ['see', 'you', 'later']}\n",
      "{'label': 'GREETING', 'text': ['good', 'afternoon']}\n",
      "{'label': 'GREETING', 'text': ['good', 'afternoon', 'hermes']}\n",
      "{'label': 'GREETING', 'text': ['good', 'evening']}\n",
      "{'label': 'GREETING', 'text': ['good', 'evening', 'hermes']}\n",
      "{'label': 'GREETING', 'text': ['good', 'morning']}\n",
      "{'label': 'GREETING', 'text': ['good', 'morning', 'hermes']}\n",
      "{'label': 'GREETING', 'text': ['hello']}\n",
      "{'label': 'GREETING', 'text': ['hello', 'hermes']}\n",
      "{'label': 'GREETING', 'text': ['hey']}\n",
      "{'label': 'GREETING', 'text': ['hey', 'hermes']}\n",
      "{'label': 'GREETING', 'text': ['hi']}\n",
      "{'label': 'GREETING', 'text': ['hi', 'hermes']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['are', 'there', 'any', 'monuments', 'around', 'here', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['are', 'there', 'any', 'museums', 'around', 'here', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['do', 'you', 'have', 'any', 'recommendation', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['do', 'you', 'have', 'any', 'suggestion', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['do', 'you', 'have', 'recommendations', 'on', 'what', 'to', 'do', 'here', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['i', 'would', 'like', 'something', 'artsy']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['i', 'would', 'like', 'to', 'know', 'if', 'there', \"'s\", 'any', 'park']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['i', 'would', 'like', 'to', 'know', 'if', 'there', \"'s\", 'any', 'zoo']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['i', \"'m\", 'looking', 'for', 'an', 'art', 'museum', 'for', 'today']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['something', 'interesting', 'for', 'children']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['we', 'would', 'like', 'somewhere', 'to', 'eat', 'afterwards']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'do', 'you', 'suggest', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'is', 'the', 'best', 'museum', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'museum', 'would', 'be', 'appropriate', 'for', 'us', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'can', 'we', 'do', 'around', 'here', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['which', 'museum', 'is', 'best', '?']}\n",
      "{'label': 'RECOMMENDATION', 'text': ['what', 'do', 'you', 'propose', '?']}\n",
      "{'label': 'REJECT', 'text': ['i', 'do', \"n't\", 'like', 'it']}\n",
      "{'label': 'REJECT', 'text': ['i', 'do', \"n't\", 'think', 'so']}\n",
      "{'label': 'REJECT', 'text': ['i', 'guess', 'not']}\n",
      "{'label': 'REJECT', 'text': ['i', \"'d\", 'rather', 'not']}\n",
      "{'label': 'REJECT', 'text': ['no']}\n",
      "{'label': 'REJECT', 'text': ['probably', 'not']}\n",
      "{'label': 'REJECT', 'text': ['does', 'not', 'sound', 'like', 'a', 'good', 'idea']}\n",
      "{'label': 'REJECT', 'text': ['can', 'you', 'recommend', 'something', 'else', '?']}\n",
      "{'label': 'REJECT', 'text': ['no', 'i', 'want', 'something', 'else']}\n",
      "{'label': 'REJECT', 'text': ['i', 'do', \"n't\", 'want', 'to', 'do', 'that']}\n",
      "{'label': 'REJECT', 'text': ['no', 'i', 'rather', 'not']}\n",
      "{'label': 'REJECT', 'text': ['not', 'a', 'good', 'idea']}\n",
      "{'label': 'REJECT', 'text': ['i', 'do', \"n't\", 'want', 'to', 'do', 'that']}\n",
      "{'label': 'REJECT', 'text': ['it', \"'s\", 'not', 'for', 'me']}\n",
      "{'label': 'REJECT', 'text': ['does', \"n't\", 'sound', 'good']}\n",
      "{'label': 'REJECT', 'text': ['do', 'you', 'have', 'other', 'recommendations']}\n",
      "{'label': 'REJECT', 'text': ['that', 'does', \"n't\", 'seem', 'cool']}\n",
      "{'label': 'REJECT', 'text': ['that', \"'s\", 'awful']}\n",
      "{'label': 'REJECT', 'text': ['we', 'would', 'like', 'better', 'ideas']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['is', 'it', 'vegetarian', 'friendly', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['can', 'i', 'walk', 'there', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['is', 'it', 'still', 'open', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['how', 'late', 'is', 'it', 'open', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['can', 'i', 'take', 'a', 'taxi', 'there', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['does', 'it', 'have', 'good', 'reviews', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['how', 'is', 'that', 'special', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['do', 'they', 'have', 'live', 'music', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['do', 'children', 'get', 'a', 'discount', 'rate', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['do', 'we', 'have', 'to', 'take', 'the', 'metro', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['how', 'can', 'i', 'get', 'there', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['is', 'it', 'far', 'from', 'here', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['is', 'it', 'good', 'for', 'children', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['is', 'it', 'open', 'on', 'sundays', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['is', 'it', 'very', 'far', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['what', 'is', 'the', 'price', '?']}\n",
      "{'label': 'REQUEST_INFO', 'text': ['what', 'is', 'the', 'timetable', '?']}\n",
      "{'label': 'THANKS', 'text': ['i', 'appreciate', 'it']}\n",
      "{'label': 'THANKS', 'text': ['you', 'were', 'wonderful']}\n",
      "{'label': 'THANKS', 'text': ['you', 'are', 'great']}\n",
      "{'label': 'THANKS', 'text': ['this', 'was', 'very', 'helpful']}\n",
      "{'label': 'THANKS', 'text': ['thank', 'you', 'for', 'your', 'help']}\n",
      "{'label': 'THANKS', 'text': ['thank', 'you', 'for', 'helping', 'us']}\n",
      "{'label': 'THANKS', 'text': ['you', 'were', 'very', 'nice']}\n",
      "{'label': 'THANKS', 'text': ['cheers']}\n",
      "{'label': 'THANKS', 'text': ['thank', 'you']}\n",
      "{'label': 'THANKS', 'text': ['thanks']}\n",
      "{'label': 'THANKS', 'text': ['thanks', 'a', 'bunch']}\n",
      "{'label': 'THANKS', 'text': ['thanks', 'a', 'lot']}\n",
      "{'label': 'THANKS', 'text': ['very', 'appreciated']}\n",
      "{'label': 'GREETING', 'text': ['good', 'afternoon']}\n"
     ]
    }
   ],
   "source": [
    "#loading custom dataset\n",
    "path = 'intent_data.csv'\n",
    "training_data=data.TabularDataset(path = path, format = 'csv', fields = fields, skip_header = True)\n",
    "\n",
    "#print preprocessed text\n",
    "for i in range(200):\n",
    "    print(vars(training_data.examples[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = training_data.split(split_ratio=0.7, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 228\n",
      "Size of LABEL vocabulary: 10\n",
      "[('i', 50), ('do', 27), ('?', 26), ('to', 22), ('you', 19), (\"n't\", 18), ('we', 17), ('like', 17), ('want', 16), ('for', 15)]\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7f2f7aa318b0>>, {'<unk>': 0, '<pad>': 1, 'i': 2, 'do': 3, '?': 4, 'to': 5, 'you': 6, \"n't\": 7, 'like': 8, 'we': 9, 'want': 10, 'for': 11, 'is': 12, 'it': 13, 'good': 14, 'that': 15, 'the': 16, 'there': 17, 'are': 18, 'my': 19, \"'s\": 20, 'a': 21, 'have': 22, 'here': 23, 'something': 24, '!': 25, 'any': 26, 'can': 27, 'museums': 28, 'not': 29, 'see': 30, 'what': 31, 'would': 32, 'great': 33, 'hello': 34, 'love': 35, 'museum': 36, 'thank': 37, 'yes': 38, \"'m\": 39, 'around': 40, 'bye': 41, 'children': 42, 'hi': 43, 'how': 44, 'later': 45, 'music': 46, 'no': 47, 'sure': 48, 'afternoon': 49, 'anything': 50, 'art': 51, 'be': 52, 'best': 53, 'course': 54, 'hate': 55, 'hermes': 56, 'looking': 57, 'loves': 58, 'of': 59, 'on': 60, 'open': 61, 'recommendation': 62, 'thanks': 63, 'us': 64, 'very': 65, 'where': 66, \"'ll\": 67, \"'re\": 68, ',': 69, 'beach': 70, 'ca': 71, 'came': 72, 'churches': 73, 'close': 74, 'cool': 75, 'cuisine': 76, 'daughter': 77, 'does': 78, 'eat': 79, 'else': 80, 'fine': 81, 'food': 82, 'hey': 83, 'if': 84, 'interesting': 85, 'know': 86, 'live': 87, 'looks': 88, 'paintings': 89, 'parks': 90, 'she': 91, 'sounds': 92, 'take': 93, 'three': 94, 'visit': 95, 'walk': 96, 'will': 97, 'wine': 98, 'yeah': 99, \"'d\": 100, 'about': 101, 'adios': 102, 'adore': 103, 'afterwards': 104, 'an': 105, 'and': 106, 'animals': 107, 'appreciate': 108, 'appreciated': 109, 'appropriate': 110, 'architecture': 111, 'ask': 112, 'awesome': 113, 'awful': 114, 'barcelona': 115, 'buildings': 116, 'bullfighting': 117, 'bunch': 118, 'cheap': 119, 'cheers': 120, 'child': 121, 'chocolate': 122, 'coffee': 123, 'come': 124, 'cost': 125, 'crowd': 126, 'dancing': 127, 'day': 128, 'days': 129, 'directions': 130, 'eight': 131, 'evening': 132, 'exactly': 133, 'expensive': 134, 'familia': 135, 'far': 136, 'favorite': 137, 'free': 138, 'french': 139, 'friendly': 140, 'friends': 141, 'get': 142, 'girlfirend': 143, 'girlfriend': 144, 'going': 145, 'group': 146, 'help': 147, 'helpful': 148, 'helping': 149, 'hundred': 150, 'husbund': 151, 'idea': 152, 'in': 153, 'join': 154, 'just': 155, 'last': 156, 'late': 157, 'likes': 158, 'listen': 159, 'local': 160, 'me': 161, 'meat': 162, 'metro': 163, 'miss': 164, 'monday': 165, 'money': 166, 'monuments': 167, 'morning': 168, 'much': 169, 'must': 170, 'newar': 171, 'nice': 172, 'now': 173, 'ok': 174, 'one': 175, 'only': 176, 'our': 177, 'outside': 178, 'park': 179, 'percent': 180, 'perfect': 181, 'prefer': 182, 'probably': 183, 'propose': 184, 'rather': 185, 'recommend': 186, 'recommendations': 187, 'restaurant': 188, 'restaurants': 189, 'right': 190, 'sagrada': 191, 'so': 192, 'some': 193, 'somewhere': 194, 'son': 195, 'sound': 196, 'special': 197, 'spend': 198, 'stand': 199, 'stay': 200, 'still': 201, 'suggestion': 202, 'sundays': 203, 'tall': 204, 'taxi': 205, 'tell': 206, 'terrific': 207, 'they': 208, 'think': 209, 'this': 210, 'tired': 211, 'today': 212, 'try': 213, 'twelve': 214, 'up': 215, 'vegetarian': 216, 'visiting': 217, 'was': 218, 'week': 219, 'weekend': 220, 'which': 221, 'with': 222, 'ya': 223, 'yep': 224, 'young': 225, 'your': 226, 'zoo': 227})\n"
     ]
    }
   ],
   "source": [
    "#initialize glove embeddings\n",
    "TEXT.build_vocab(train_data,min_freq=0,vectors = \"glove.6B.100d\")  \n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "print(TEXT.vocab.stoi)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether cuda is available\n",
    "device = torch.device('cpu')  \n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "#Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Softmax()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "size_of_vocab = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "num_hidden_nodes = 30\n",
    "num_output_nodes = 10\n",
    "num_layers = 1\n",
    "bidirection = True\n",
    "dropout = 0\n",
    "\n",
    "#instantiate the model\n",
    "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
    "                   bidirectional = True, dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(228, 100)\n",
      "  (lstm): LSTM(100, 30, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=60, out_features=10, bias=True)\n",
      "  (act): Softmax(dim=None)\n",
      ")\n",
      "The model has 55,090 trainable parameters\n",
      "torch.Size([228, 100])\n"
     ]
    }
   ],
   "source": [
    "#architecture\n",
    "print(model)\n",
    "\n",
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "#push to cuda if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        #retrieve text and no. of words\n",
    "        text, text_lengths = batch.text   \n",
    "        \n",
    "        #convert to 1D tensor\n",
    "        predictions = model(text, text_lengths).squeeze()  \n",
    "        \n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, batch.label.type(torch.LongTensor))        \n",
    "    \n",
    "        #compute the binary accuracy\n",
    "        \n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()       \n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    #initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    #deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            #retrieve text and no. of words\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            #convert to 1d tensor\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "            \n",
    "            #compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.label.type(torch.LongTensor))\n",
    "            \n",
    "            #keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(model, iterator):\n",
    "    correct_count = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    #deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            #retrieve text and no. of words\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            #convert to 1d tensor\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "            _, pred = torch.max(predictions, -1)\n",
    "            correct_count += (pred == batch.label).sum()            \n",
    "        \n",
    "    return correct_count / len(valid_data), '%'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9fce78094710>:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs=self.act(dense_outputs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_EPOCHS = 700\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    #print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    train_loss_list.append(train_loss)\n",
    "    #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    test_loss_list.append(valid_loss)\n",
    "    \n",
    "plt.plot(train_loss_list, label = 'train')\n",
    "plt.plot(test_loss_list, label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9fce78094710>:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs=self.act(dense_outputs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.6712), '%')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_acc(model, valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spend = 0.2787282466888428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9fce78094710>:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs=self.act(dense_outputs)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_0 = time.time()\n",
    "#load weights\n",
    "path='saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path));\n",
    "model.eval();\n",
    "\n",
    "#inference \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def predict(model, sentence):\n",
    "    tokenized = [tok.text.lower() for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n",
    "    length = [len(indexed)]                                    #compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
    "    prediction = model(tensor, length_tensor)                  #prediction \n",
    "    return 'Intent:' , list(LABEL.vocab.stoi)[torch.argmax(prediction)]\n",
    "\n",
    "\n",
    "predict(model, \"I don't like museums\")\n",
    "time_1 = time.time()\n",
    "print('Total time spend =', time_1 - time_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9fce78094710>:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs=self.act(dense_outputs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Intent:', 'ADD_INFO')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"I like moder art\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'CONFIRM': 0,\n",
       "             'ADD_INFO': 1,\n",
       "             'RECOMMENDATION': 2,\n",
       "             'GREETING': 3,\n",
       "             'ADD_INFO_NEG': 4,\n",
       "             'REJECT': 5,\n",
       "             'REQUEST_INFO': 6,\n",
       "             'ADD_INFO_POS': 7,\n",
       "             'THANKS': 8,\n",
       "             'GOODBYE': 9})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
